{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# Music channels reporting\n",
    "------------------------\n",
    "\n",
    "Illustrated report on the contribution of YouTube music channels to my â€œmusical assetsâ€ over the last few years (from 2022 to today).\n",
    "\n",
    "## Introduction\n",
    "\n",
    "The aim of this notebook is quite simple: to summarize and illustrate the importance of music channels in their daily  contribution to my personal listening. With a long-format listening process automated for almost 3 years at the time of writing (January 7th, 2025), and a single-track listening process automated since January 1st, 2024 (accompanied by metrics collection), it was time to create this new process, which this time will enable me to adjust daily listening sources.\n",
    "\n",
    "In other words, a new way of choosing which music channels to follow, or not. Channel selection will be based on the following playlists:\n",
    "\n",
    "* [ðŸ”‚ Re-listening](https://www.youtube.com/playlist?list=PLOMUdQFdS-XP8fi89uBQ5P01DN_9tGJHu) (Private): A playlist of all the re-listens I need to do.\n",
    "* [ðŸ–¤ 2022 by dyl_m](https://www.youtube.com/playlist?list=PLOMUdQFdS-XMikLg-T7EuUAnCPdGbTAAJ)\n",
    "* [ðŸ–¤ 2023 by dyl_m](https://www.youtube.com/playlist?list=PLOMUdQFdS-XPGM7HHAX9hVb5lVEKSPnK3)\n",
    "* [ðŸ–¤ 2024 by dyl_m](https://www.youtube.com/playlist?list=PLOMUdQFdS-XNqUpFzE89aHgwn0wrBidyG)\n",
    "* [ðŸ–¤ 2025 by dyl_m](https://www.youtube.com/playlist?list=PLOMUdQFdS-XMfbJk0XdreFpdm2CRCGC-e)\n",
    "* [ðŸ–¤ 2026 by dyl_m](https://www.youtube.com/playlist?list=PLOMUdQFdS-XN52B4qKx4oKf5EfW1lBm--)\n",
    "\n",
    "Former playlist used:\n",
    "* [ðŸ–¤ 2021 by dyl_m](https://www.youtube.com/playlist?list=PLOMUdQFdS-XMaC0KBG2EN8lnwkdShXSk9)"
   ],
   "id": "585ea8291d9c00fa"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Dependencies",
   "id": "6557bb454f8850d2"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import datetime as dt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import json\n",
    "import plotly.express as px\n",
    "import pyyoutube as pyt\n",
    "import sys\n",
    "\n",
    "import yrt.youtube as s_yt\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler"
   ],
   "id": "ebff62cde95b2c7b",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "SERVICE = s_yt.create_service_local(log=False)  # Create the YouTube API Client prior any API request",
   "id": "4789b5be9adb29b1",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "with open('../_config/pocket_tube.json', 'r', encoding='utf-8') as j_file:\n",
    "    local_db = json.load(j_file)['MUSIQUE']"
   ],
   "id": "bbbac1eb923c5f28",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Functions",
   "id": "a7c45eb7c287fa1c"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "def get_playlists_content(service: pyt.Client, playlist_id: str) -> list:\n",
    "    \"\"\"Get the videos in a YouTube playlist\n",
    "    :param service: a Python YouTube Client\n",
    "    :param playlist_id: a YouTube playlist ID\n",
    "    :return p_items: playlist items (videos) as a list.\n",
    "    \"\"\"\n",
    "    p_items = []\n",
    "    next_page_token = None\n",
    "    date_format = '%Y-%m-%dT%H:%M:%S%z'\n",
    "\n",
    "    while True:\n",
    "        try:\n",
    "            request = service.playlistItems.list(part=['snippet', 'contentDetails'],\n",
    "                                                 playlist_id=playlist_id,\n",
    "                                                 max_results=50,\n",
    "                                                 pageToken=next_page_token)  # Request playlist's items\n",
    "\n",
    "            # Keep necessary _data\n",
    "            p_items += [{'video_id': item.contentDetails.videoId,\n",
    "                         'video_title': item.snippet.title,\n",
    "                         'release_date': dt.datetime.strptime(item.contentDetails.videoPublishedAt, date_format) if\n",
    "                         item.contentDetails.videoPublishedAt else None,\n",
    "                         'channel_id': item.snippet.videoOwnerChannelId,\n",
    "                         'channel_name': item.snippet.videoOwnerChannelTitle,\n",
    "                         'playlist_id': playlist_id} for item in request.items]\n",
    "\n",
    "            next_page_token = request.nextPageToken\n",
    "            if next_page_token is None:\n",
    "                break\n",
    "\n",
    "        except pyt.error.PyYouTubeException as error:\n",
    "            print(f'{error.status_code}: {error.message}')\n",
    "            sys.exit()\n",
    "\n",
    "    return p_items"
   ],
   "id": "13ea24dfe957d069",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "def get_channels(service: pyt.Client, channel_list: list) -> list:\n",
    "    \"\"\"Get YouTube channels basic information\n",
    "    :param service: a YouTube service build with 'googleapiclient.discovery'\n",
    "    :param channel_list: list of YouTube channel ID\n",
    "    :return information: a dictionary with channels names, IDs and uploads playlist IDs.\n",
    "    \"\"\"\n",
    "    information = []\n",
    "\n",
    "    # Split task in chunks of size 50 to request on a maximum of 50 channels at each iteration.\n",
    "    channels_chunks = [channel_list[i:i + min(50, len(channel_list))] for i in range(0, len(channel_list), 50)]\n",
    "\n",
    "    for chunk in channels_chunks:\n",
    "        try:\n",
    "            # Request channels\n",
    "            request = service.channels.list(part=['snippet'], channel_id=chunk, max_results=50).items\n",
    "\n",
    "            # Extract upload playlists, channel names and their ID.\n",
    "            information += [{'channel_name': an_item.snippet.title, 'channel_id': an_item.id} for an_item in request]\n",
    "\n",
    "        except pyt.error.PyYouTubeException as error:\n",
    "            print(f'{error.status_code}: {error.message}')\n",
    "            sys.exit()\n",
    "\n",
    "    # Sort by channel name alphabetical order\n",
    "    information = sorted(information, key=lambda dic: dic['channel_name'].lower())\n",
    "\n",
    "    return information"
   ],
   "id": "f702508b96e296e7",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Reporting\n",
    "\n",
    "### Data collection"
   ],
   "id": "ceb345575b6ac7d3"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Playlist IDs\n",
    "ids = {'music_2022': 'PLOMUdQFdS-XMikLg-T7EuUAnCPdGbTAAJ',\n",
    "       'music_2023': 'PLOMUdQFdS-XPGM7HHAX9hVb5lVEKSPnK3',\n",
    "       'music_2024': 'PLOMUdQFdS-XNqUpFzE89aHgwn0wrBidyG',\n",
    "       'music_2025': 'PLOMUdQFdS-XMfbJk0XdreFpdm2CRCGC-e',\n",
    "       'music_2026': 'PLOMUdQFdS-XN52B4qKx4oKf5EfW1lBm--',\n",
    "       're_listening': 'PLOMUdQFdS-XP8fi89uBQ5P01DN_9tGJHu'}\n",
    "\n",
    "rev_ids = {value: key for key, value in ids.items()}  # Reversed dict. for labeling"
   ],
   "id": "f9d2131e249be3a3",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "music_2022 = pd.DataFrame(get_playlists_content(SERVICE, playlist_id=ids['music_2022']))\n",
    "music_2023 = pd.DataFrame(get_playlists_content(SERVICE, playlist_id=ids['music_2023']))\n",
    "music_2024 = pd.DataFrame(get_playlists_content(SERVICE, playlist_id=ids['music_2024']))\n",
    "music_2025 = pd.DataFrame(get_playlists_content(SERVICE, playlist_id=ids['music_2025']))\n",
    "music_2026 = pd.DataFrame(get_playlists_content(SERVICE, playlist_id=ids['music_2026']))\n",
    "re_listening = pd.DataFrame(get_playlists_content(SERVICE, playlist_id=ids['re_listening']))\n",
    "\n",
    "# All data\n",
    "data = pd.concat([music_2022, music_2023, music_2024, music_2025, music_2026, re_listening]). \\\n",
    "    sort_values(['release_date', 'video_id'], ascending=False, ignore_index=True).dropna()\n",
    "\n",
    "# Without re-listening\n",
    "selection = pd.concat([music_2022, music_2023, music_2024, music_2025, music_2026]). \\\n",
    "    sort_values(['release_date', 'video_id'], ascending=False, ignore_index=True).dropna()\n",
    "\n",
    "data.replace({'playlist_id': rev_ids}, inplace=True)\n",
    "selection.replace({'playlist_id': rev_ids}, inplace=True)"
   ],
   "id": "7a4bc8c242ee41fd",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "data",
   "id": "b939fbcc69df584a",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "selection",
   "id": "3b4db0bd5cefad82",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Release Dates Distribution",
   "id": "63208f56473618df"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "release_date_his = px.histogram(data, 'release_date', title='Videos Release Dates Distribution', labels={'release_date': 'Release Date'})\n",
    "release_date_his.show()"
   ],
   "id": "553d14edcfe99bbe",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "sel_release_date_his = px.histogram(selection, 'release_date', title='Videos Release Dates Distribution',\n",
    "                                    labels={'release_date': 'Release Date'})\n",
    "sel_release_date_his.show()"
   ],
   "id": "926079248a6f4b7a",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### Count of videos by channel\n",
    "#### Channel Database"
   ],
   "id": "eb816a88b655c6b1"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "channel_from_pl = data[['channel_id', 'channel_name']] \\\n",
    "    .drop_duplicates() \\\n",
    "    .sort_values('channel_name', ignore_index=True)\n",
    "\n",
    "channel_from_local = pd.DataFrame(get_channels(SERVICE, local_db))\n",
    "channel_from_local"
   ],
   "id": "da9868fe38d64965",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "#### Count by videos\n",
    "##### All playlists"
   ],
   "id": "b59aa65b6434c8a"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "chan_count = data.groupby('channel_id')['video_id'].count()\n",
    "\n",
    "chan_names = data[['channel_id', 'channel_name']] \\\n",
    "    .drop_duplicates() \\\n",
    "    .sort_values('channel_name', ignore_index=True)\n",
    "\n",
    "chan_count = pd.DataFrame(chan_count) \\\n",
    "    .merge(chan_names, how='left', on='channel_id')[['channel_id', 'channel_name', 'video_id']] \\\n",
    "    .rename(columns={'video_id': 'n_videos'}) \\\n",
    "    .sort_values('n_videos', ascending=False, ignore_index=True)\n",
    "\n",
    "chan_count"
   ],
   "id": "2f55f2fcf86023ad",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "##### Without re-listening",
   "id": "51122058fa34ce63"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "sel_chan_count = selection.groupby('channel_id')['video_id'].count()\n",
    "\n",
    "sel_chan_count = pd.DataFrame(sel_chan_count) \\\n",
    "    .merge(chan_names, how='left', on='channel_id')[['channel_id', 'channel_name', 'video_id']] \\\n",
    "    .rename(columns={'video_id': 'n_videos_fil'}) \\\n",
    "    .sort_values('n_videos_fil', ascending=False, ignore_index=True)\n",
    "\n",
    "sel_chan_count"
   ],
   "id": "f089268e9d22639e",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "#### Weight based on Release Date\n",
    "##### All playlists"
   ],
   "id": "ba3a86e7d7e590a8"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "scaler = StandardScaler()\n",
    "data['date_weight'] = np.exp(scaler.fit_transform(data.release_date \\\n",
    "                                                  .astype('int') \\\n",
    "                                                  .to_numpy() \\\n",
    "                                                  .reshape(-1, 1)))\n",
    "\n",
    "data_w = data.groupby('channel_id')['date_weight'].sum()\n",
    "\n",
    "data_w = pd.DataFrame(data_w) \\\n",
    "    .merge(chan_names, how='left', on='channel_id')[['channel_id', 'channel_name', 'date_weight']] \\\n",
    "    .sort_values('date_weight', ascending=False, ignore_index=True)\n",
    "\n",
    "data_w"
   ],
   "id": "77777c33898e34f4",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "##### Without re-listening",
   "id": "758a503b562af140"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "selection['date_weight'] = np.exp(scaler.fit_transform(selection.release_date \\\n",
    "                                                       .astype('int') \\\n",
    "                                                       .to_numpy() \\\n",
    "                                                       .reshape(-1, 1)))\n",
    "\n",
    "selection_w = selection.groupby('channel_id')['date_weight'].sum()\n",
    "\n",
    "selection_w = pd.DataFrame(selection_w) \\\n",
    "    .merge(chan_names, how='left', on='channel_id')[['channel_id', 'channel_name', 'date_weight']] \\\n",
    "    .rename(columns={'date_weight': 'date_weight_fil'}) \\\n",
    "    .sort_values('date_weight_fil', ascending=False, ignore_index=True)\n",
    "\n",
    "selection_w"
   ],
   "id": "6fffb48800a73d41",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### All metrics and classification",
   "id": "8ca3adfb2a3f3777"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "metrics = chan_count.merge(sel_chan_count, how='left', on=['channel_id', 'channel_name']) \\\n",
    "    .merge(data_w, how='left', on=['channel_id', 'channel_name']) \\\n",
    "    .merge(selection_w, how='left', on=['channel_id', 'channel_name']) \\\n",
    "    .fillna(0) \\\n",
    "    .sort_values(['n_videos', 'n_videos_fil', 'date_weight', 'date_weight_fil'], ascending=False, ignore_index=True)\n",
    "\n",
    "metrics"
   ],
   "id": "9d2086b3e7b0e7a8",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "#### To add to Favorites\n",
    "\n",
    "Channels to add to Favorites selection based on a number of uploads significantly high."
   ],
   "id": "826dcc34eb642da5"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "nv_95 = float(metrics.n_videos.quantile(0.95))\n",
    "nvf_95 = float(metrics.n_videos_fil.quantile(0.95))\n",
    "dw_95 = float(metrics.date_weight.quantile(0.95))\n",
    "dwf_95 = float(metrics.date_weight_fil.quantile(0.95))\n",
    "\n",
    "favorites = metrics.loc[(metrics['n_videos'] >= nv_95) &\n",
    "                        (metrics['n_videos_fil'] >= nvf_95) &\n",
    "                        (metrics['date_weight'] >= dw_95) &\n",
    "                        (metrics['date_weight_fil'] >= dwf_95), :]\n",
    "\n",
    "print(favorites[['channel_name', 'channel_id']])"
   ],
   "id": "87067aa23493af98",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "#### To add to Database\n",
    "\n",
    "Channels that could be considerate for an addition into the Database."
   ],
   "id": "bcb30bb9232074aa"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "nv_75 = float(metrics.n_videos.quantile(0.75))\n",
    "nvf_75 = float(metrics.n_videos_fil.quantile(0.75))\n",
    "dw_75 = float(metrics.date_weight.quantile(0.75))\n",
    "dwf_75 = float(metrics.date_weight_fil.quantile(0.75))\n",
    "\n",
    "not_following = metrics.loc[~metrics.channel_id.isin(channel_from_local.channel_id), :]\n",
    "\n",
    "to_follow = not_following.loc[(not_following['n_videos'] > nv_75) &\n",
    "                              (not_following['n_videos_fil'] > nvf_75) &\n",
    "                              (not_following['date_weight'] > dw_75) &\n",
    "                              (not_following['date_weight_fil'] > dwf_75), :]\n",
    "\n",
    "print(to_follow[['channel_name', 'channel_id']])"
   ],
   "id": "e15d23ff903bfb15",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "#### \"Uninteresting\" channels\n",
    "\n",
    "All the channels bringing not so much music for the past few years. Will be removed from the Database and surely\n",
    "moved to \"Certified\" status."
   ],
   "id": "300398f42c0396ac"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "dw_25 = float(metrics.date_weight.quantile(0.25))\n",
    "dwf_25 = float(metrics.date_weight_fil.quantile(0.25))\n",
    "\n",
    "listed = metrics.loc[metrics.channel_id.isin(channel_from_local.channel_id), :]\n",
    "uninteresting = listed.loc[(listed['date_weight'] <= dw_25) &\n",
    "                           (listed['date_weight_fil'] <= dwf_25), :]\n",
    "\n",
    "print(uninteresting[['channel_name', 'channel_id']])"
   ],
   "id": "d9b60040820731a9",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "#### Unlisted in playlists\n",
    "\n",
    "All the channels not listed in playlists explored. Perhaps, I have to removed them from the Database."
   ],
   "id": "8493799b90c02033"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "unlisted = channel_from_local.loc[~channel_from_local.channel_id.isin(metrics.channel_id),:]\n",
    "print(unlisted)"
   ],
   "id": "f298b78c165e664e",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python3",
   "language": "python",
   "display_name": "Python 3 (ipykernel)"
  }
 },
 "nbformat": 5,
 "nbformat_minor": 9
}
