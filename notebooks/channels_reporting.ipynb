{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# Music channels reporting\n",
    "------------------------\n",
    "\n",
    "Illustrated report on the contribution of YouTube music channels to my “musical assets” over the last few years (from 2021 to today).\n",
    "\n",
    "## Introduction\n",
    "\n",
    "The aim of this notebook is quite simple: to summarize and illustrate the importance of music channels in their daily\n",
    " contribution to my personal listening. With a long-format listening process automated for almost 3 years at the time\n",
    "  of writing (January 7th, 2025), and a single-track listening process automated since January 1st, 2024\n",
    "  (accompanied\n",
    "  by metrics collection), it was time to create this new process, which this time will enable me to adjust daily listening sources.\n",
    "\n",
    "In other words, a new way of choosing which music channels to follow, or not. Channel selection will be based on the\n",
    "following playlists:\n",
    "\n",
    "* [🔂 Re-listening](https://www.youtube.com/playlist?list=PLOMUdQFdS-XP8fi89uBQ5P01DN_9tGJHu) (Private): A playlist of all the re-listens I need to do.\n",
    "* [💙 2021 by dyl_m](https://www.youtube.com/playlist?list=PLOMUdQFdS-XMaC0KBG2EN8lnwkdShXSk9)\n",
    "* [💙 2022 by dyl_m](https://www.youtube.com/playlist?list=PLOMUdQFdS-XMikLg-T7EuUAnCPdGbTAAJ)\n",
    "* [💙 2023 by dyl_m](https://www.youtube.com/playlist?list=PLOMUdQFdS-XPGM7HHAX9hVb5lVEKSPnK3)\n",
    "* [💙 2024 by dyl_m](https://www.youtube.com/playlist?list=PLOMUdQFdS-XNqUpFzE89aHgwn0wrBidyG)\n",
    "* [💙 2025 by dyl_m](https://www.youtube.com/playlist?list=PLOMUdQFdS-XMfbJk0XdreFpdm2CRCGC-e)"
   ],
   "id": "585ea8291d9c00fa"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Dependencies",
   "id": "6557bb454f8850d2"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import datetime as dt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import json\n",
    "import plotly.express as px\n",
    "import pyyoutube as pyt\n",
    "import sys\n",
    "\n",
    "import src.youtube as s_yt\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler"
   ],
   "id": "ebff62cde95b2c7b",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "SERVICE = s_yt.create_service_local(log=False)  # Create the YouTube API Client prior any API request",
   "id": "4789b5be9adb29b1",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "with open('../data/pocket_tube.json', 'r', encoding='utf-8') as j_file:\n",
    "    local_db = json.load(j_file)['MUSIQUE']"
   ],
   "id": "bbbac1eb923c5f28",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Functions",
   "id": "a7c45eb7c287fa1c"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "def get_playlists_content(service: pyt.Client, playlist_id: str) -> list:\n",
    "    \"\"\"Get the videos in a YouTube playlist\n",
    "    :param service: a Python YouTube Client\n",
    "    :param playlist_id: a YouTube playlist ID\n",
    "    :return p_items: playlist items (videos) as a list.\n",
    "    \"\"\"\n",
    "    p_items = []\n",
    "    next_page_token = None\n",
    "    date_format = '%Y-%m-%dT%H:%M:%S%z'\n",
    "\n",
    "    while True:\n",
    "        try:\n",
    "            request = service.playlistItems.list(part=['snippet', 'contentDetails'],\n",
    "                                                 playlist_id=playlist_id,\n",
    "                                                 max_results=50,\n",
    "                                                 pageToken=next_page_token)  # Request playlist's items\n",
    "\n",
    "            # Keep necessary data\n",
    "            p_items += [{'video_id': item.contentDetails.videoId,\n",
    "                         'video_title': item.snippet.title,\n",
    "                         'release_date': dt.datetime.strptime(item.contentDetails.videoPublishedAt, date_format) if\n",
    "                         item.contentDetails.videoPublishedAt else None,\n",
    "                         'channel_id': item.snippet.videoOwnerChannelId,\n",
    "                         'channel_name': item.snippet.videoOwnerChannelTitle,\n",
    "                         'playlist_id': playlist_id} for item in request.items]\n",
    "\n",
    "            next_page_token = request.nextPageToken\n",
    "            if next_page_token is None:\n",
    "                break\n",
    "\n",
    "        except pyt.error.PyYouTubeException as error:\n",
    "            print(f'{error.status_code}: {error.message}')\n",
    "            sys.exit()\n",
    "\n",
    "    return p_items"
   ],
   "id": "13ea24dfe957d069",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "def get_channels(service: pyt.Client, channel_list: list) -> list:\n",
    "    \"\"\"Get YouTube channels basic information\n",
    "    :param service: a YouTube service build with 'googleapiclient.discovery'\n",
    "    :param channel_list: list of YouTube channel ID\n",
    "    :return information: a dictionary with channels names, IDs and uploads playlist IDs.\n",
    "    \"\"\"\n",
    "    information = []\n",
    "\n",
    "    # Split task in chunks of size 50 to request on a maximum of 50 channels at each iteration.\n",
    "    channels_chunks = [channel_list[i:i + min(50, len(channel_list))] for i in range(0, len(channel_list), 50)]\n",
    "\n",
    "    for chunk in channels_chunks:\n",
    "        try:\n",
    "            # Request channels\n",
    "            request = service.channels.list(part=['snippet'], channel_id=chunk, max_results=50).items\n",
    "\n",
    "            # Extract upload playlists, channel names and their ID.\n",
    "            information += [{'channel_name': an_item.snippet.title, 'channel_id': an_item.id} for an_item in request]\n",
    "\n",
    "        except pyt.error.PyYouTubeException as error:\n",
    "            print(f'{error.status_code}: {error.message}')\n",
    "            sys.exit()\n",
    "\n",
    "    # Sort by channel name alphabetical order\n",
    "    information = sorted(information, key=lambda dic: dic['channel_name'].lower())\n",
    "\n",
    "    return information"
   ],
   "id": "f702508b96e296e7",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Reporting\n",
    "\n",
    "### Data collection"
   ],
   "id": "ceb345575b6ac7d3"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Playlist IDs\n",
    "ids = {'music_2021': 'PLOMUdQFdS-XMaC0KBG2EN8lnwkdShXSk9',\n",
    "       'music_2022': 'PLOMUdQFdS-XMikLg-T7EuUAnCPdGbTAAJ',\n",
    "       'music_2023': 'PLOMUdQFdS-XPGM7HHAX9hVb5lVEKSPnK3',\n",
    "       'music_2024': 'PLOMUdQFdS-XNqUpFzE89aHgwn0wrBidyG',\n",
    "       'music_2025': 'PLOMUdQFdS-XMfbJk0XdreFpdm2CRCGC-e',\n",
    "       're_listening': 'PLOMUdQFdS-XP8fi89uBQ5P01DN_9tGJHu'}\n",
    "\n",
    "rev_ids = {value: key for key, value in ids.items()}  # Reversed dict. for labeling"
   ],
   "id": "f9d2131e249be3a3",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "music_2021 = pd.DataFrame(get_playlists_content(SERVICE, playlist_id=ids['music_2021']))\n",
    "music_2022 = pd.DataFrame(get_playlists_content(SERVICE, playlist_id=ids['music_2022']))\n",
    "music_2023 = pd.DataFrame(get_playlists_content(SERVICE, playlist_id=ids['music_2023']))\n",
    "music_2024 = pd.DataFrame(get_playlists_content(SERVICE, playlist_id=ids['music_2024']))\n",
    "music_2025 = pd.DataFrame(get_playlists_content(SERVICE, playlist_id=ids['music_2025']))\n",
    "re_listening = pd.DataFrame(get_playlists_content(SERVICE, playlist_id=ids['re_listening']))\n",
    "\n",
    "# All data\n",
    "data = pd.concat([music_2021, music_2022, music_2023, music_2024, music_2025, re_listening]). \\\n",
    "    sort_values(['release_date', 'video_id'], ascending=False, ignore_index=True).dropna()\n",
    "\n",
    "# Without re-listening\n",
    "selection = pd.concat([music_2021, music_2022, music_2023, music_2024, music_2025]). \\\n",
    "    sort_values(['release_date', 'video_id'], ascending=False, ignore_index=True).dropna()\n",
    "\n",
    "data.replace({'playlist_id': rev_ids}, inplace=True)\n",
    "selection.replace({'playlist_id': rev_ids}, inplace=True)"
   ],
   "id": "7a4bc8c242ee41fd",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "data",
   "id": "b939fbcc69df584a",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "selection",
   "id": "3b4db0bd5cefad82",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Release Dates Distribution",
   "id": "63208f56473618df"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "release_date_his = px.histogram(data, 'release_date', title='Videos Release Dates Distribution', labels={'release_date': 'Release Date'})\n",
    "release_date_his.show()"
   ],
   "id": "553d14edcfe99bbe",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "sel_release_date_his = px.histogram(selection, 'release_date', title='Videos Release Dates Distribution',\n",
    "                                    labels={'release_date': 'Release Date'})\n",
    "sel_release_date_his.show()"
   ],
   "id": "926079248a6f4b7a",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### Count of videos by channel\n",
    "#### Channel Database"
   ],
   "id": "eb816a88b655c6b1"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "channel_from_pl = data[['channel_id', 'channel_name']] \\\n",
    "    .drop_duplicates() \\\n",
    "    .sort_values('channel_name', ignore_index=True)\n",
    "\n",
    "channel_from_local = pd.DataFrame(get_channels(SERVICE, local_db))\n",
    "channel_from_local"
   ],
   "id": "da9868fe38d64965",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "#### Count by videos\n",
    "##### All playlists"
   ],
   "id": "b59aa65b6434c8a"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "chan_count = data.groupby('channel_id')['video_id'].count()\n",
    "\n",
    "chan_names = data[['channel_id', 'channel_name']] \\\n",
    "    .drop_duplicates() \\\n",
    "    .sort_values('channel_name', ignore_index=True)\n",
    "\n",
    "chan_count = pd.DataFrame(chan_count) \\\n",
    "    .merge(chan_names, how='left', on='channel_id')[['channel_id', 'channel_name', 'video_id']] \\\n",
    "    .rename(columns={'video_id': 'n_videos'}) \\\n",
    "    .sort_values('n_videos', ascending=False, ignore_index=True)\n",
    "\n",
    "chan_count"
   ],
   "id": "2f55f2fcf86023ad",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "##### Without re-listening",
   "id": "51122058fa34ce63"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "sel_chan_count = selection.groupby('channel_id')['video_id'].count()\n",
    "\n",
    "sel_chan_count = pd.DataFrame(sel_chan_count) \\\n",
    "    .merge(chan_names, how='left', on='channel_id')[['channel_id', 'channel_name', 'video_id']] \\\n",
    "    .rename(columns={'video_id': 'n_videos_fil'}) \\\n",
    "    .sort_values('n_videos_fil', ascending=False, ignore_index=True)\n",
    "\n",
    "sel_chan_count"
   ],
   "id": "f089268e9d22639e",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "#### Weight based on Release Date\n",
    "##### All playlists"
   ],
   "id": "ba3a86e7d7e590a8"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "scaler = StandardScaler()\n",
    "data['date_weight'] = np.exp(scaler.fit_transform(data.release_date \\\n",
    "                                                  .astype('int') \\\n",
    "                                                  .to_numpy() \\\n",
    "                                                  .reshape(-1, 1)))\n",
    "\n",
    "data_w = data.groupby('channel_id')['date_weight'].sum()\n",
    "\n",
    "data_w = pd.DataFrame(data_w) \\\n",
    "    .merge(chan_names, how='left', on='channel_id')[['channel_id', 'channel_name', 'date_weight']] \\\n",
    "    .sort_values('date_weight', ascending=False, ignore_index=True)\n",
    "\n",
    "data_w"
   ],
   "id": "77777c33898e34f4",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "##### Without re-listening",
   "id": "758a503b562af140"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "selection['date_weight'] = np.exp(scaler.fit_transform(selection.release_date \\\n",
    "                                                       .astype('int') \\\n",
    "                                                       .to_numpy() \\\n",
    "                                                       .reshape(-1, 1)))\n",
    "\n",
    "selection_w = selection.groupby('channel_id')['date_weight'].sum()\n",
    "\n",
    "selection_w = pd.DataFrame(selection_w) \\\n",
    "    .merge(chan_names, how='left', on='channel_id')[['channel_id', 'channel_name', 'date_weight']] \\\n",
    "    .rename(columns={'date_weight': 'date_weight_fil'}) \\\n",
    "    .sort_values('date_weight_fil', ascending=False, ignore_index=True)\n",
    "\n",
    "selection_w"
   ],
   "id": "6fffb48800a73d41",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### All metrics and classification",
   "id": "8ca3adfb2a3f3777"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "metrics = chan_count.merge(sel_chan_count, how='left', on=['channel_id', 'channel_name']) \\\n",
    "    .merge(data_w, how='left', on=['channel_id', 'channel_name']) \\\n",
    "    .merge(selection_w, how='left', on=['channel_id', 'channel_name']) \\\n",
    "    .fillna(0) \\\n",
    "    .sort_values(['n_videos', 'n_videos_fil', 'date_weight', 'date_weight_fil'], ascending=False, ignore_index=True)\n",
    "\n",
    "metrics"
   ],
   "id": "9d2086b3e7b0e7a8",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "#### To add to Favorites\n",
    "\n",
    "Channels to add to Favorites selection based on a number of uploads significantly high."
   ],
   "id": "826dcc34eb642da5"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "nv_95 = float(metrics.n_videos.quantile(0.95))\n",
    "nvf_95 = float(metrics.n_videos_fil.quantile(0.95))\n",
    "dw_95 = float(metrics.date_weight.quantile(0.95))\n",
    "dwf_95 = float(metrics.date_weight_fil.quantile(0.95))\n",
    "\n",
    "favorites = metrics.loc[(metrics['n_videos'] >= nv_95) &\n",
    "                        (metrics['n_videos_fil'] >= nvf_95) &\n",
    "                        (metrics['date_weight'] >= dw_95) &\n",
    "                        (metrics['date_weight_fil'] >= dwf_95), :]\n",
    "\n",
    "print(favorites[['channel_name', 'channel_id']])"
   ],
   "id": "87067aa23493af98",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "#### To add to Database\n",
    "\n",
    "Channels that could be considerate for an addition into the Database."
   ],
   "id": "bcb30bb9232074aa"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "nv_75 = float(metrics.n_videos.quantile(0.75))\n",
    "nvf_75 = float(metrics.n_videos_fil.quantile(0.75))\n",
    "dw_75 = float(metrics.date_weight.quantile(0.75))\n",
    "dwf_75 = float(metrics.date_weight_fil.quantile(0.75))\n",
    "\n",
    "not_following = metrics.loc[~metrics.channel_id.isin(channel_from_local.channel_id), :]\n",
    "\n",
    "to_follow = not_following.loc[(not_following['n_videos'] > nv_75) &\n",
    "                              (not_following['n_videos_fil'] > nvf_75) &\n",
    "                              (not_following['date_weight'] > dw_75) &\n",
    "                              (not_following['date_weight_fil'] > dwf_75), :]\n",
    "\n",
    "print(to_follow[['channel_name', 'channel_id']])"
   ],
   "id": "e15d23ff903bfb15",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "#### \"Uninteresting\" channels\n",
    "\n",
    "All the channels bringing not so much music for the past few years. Will be removed from the Database and surely\n",
    "moved to \"Certified\" status."
   ],
   "id": "300398f42c0396ac"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "dw_25 = float(metrics.date_weight.quantile(0.25))\n",
    "dwf_25 = float(metrics.date_weight_fil.quantile(0.25))\n",
    "\n",
    "listed = metrics.loc[metrics.channel_id.isin(channel_from_local.channel_id), :]\n",
    "uninteresting = listed.loc[(listed['date_weight'] <= dw_25) &\n",
    "                           (listed['date_weight_fil'] <= dwf_25), :]\n",
    "\n",
    "print(uninteresting[['channel_name', 'channel_id']])"
   ],
   "id": "d9b60040820731a9",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "#### Unlisted in playlists\n",
    "\n",
    "All the channels not listed in playlists explored. Perhaps, I have to removed them from the Database."
   ],
   "id": "8493799b90c02033"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "unlisted = channel_from_local.loc[~channel_from_local.channel_id.isin(metrics.channel_id),:]\n",
    "print(unlisted)"
   ],
   "id": "f298b78c165e664e",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python3",
   "language": "python",
   "display_name": "Python 3 (ipykernel)"
  }
 },
 "nbformat": 5,
 "nbformat_minor": 9
}
